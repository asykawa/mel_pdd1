import io
from pathlib import Path
import torch
import torch.nn as nn
from fastapi import APIRouter, File, UploadFile, HTTPException
from torchvision import transforms
from PIL import Image

# ================= PATH =================
BASE_DIR = Path(__file__).resolve().parent.parent.parent
MODEL_PATH = BASE_DIR / "melis_model.pth"

model_router = APIRouter(prefix='/model', tags=['Model'])

# ================= CLASSES =================
class_names = [
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (20 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (30 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (50 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (60 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (70 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (80 –∫–º/—á)',
    '–ö–æ–Ω–µ—Ü –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (80 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (100 –∫–º/—á)',
    '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (120 –∫–º/—á)',
    '–û–±–≥–æ–Ω –∑–∞–ø—Ä–µ—â—ë–Ω',
    '–û–±–≥–æ–Ω –∑–∞–ø—Ä–µ—â—ë–Ω –¥–ª—è –¢–° –±–æ–ª–µ–µ 3,5 —Ç–æ–Ω–Ω',
    '–ì–ª–∞–≤–Ω–∞—è –¥–æ—Ä–æ–≥–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–∫–µ',
    '–ì–ª–∞–≤–Ω–∞—è –¥–æ—Ä–æ–≥–∞',
    '–£—Å—Ç—É–ø–∏—Ç–µ –¥–æ—Ä–æ–≥—É',
    '–°—Ç–æ–ø',
    '–î–≤–∏–∂–µ–Ω–∏–µ –∑–∞–ø—Ä–µ—â–µ–Ω–æ',
    '–î–≤–∏–∂–µ–Ω–∏–µ –¢–° –±–æ–ª–µ–µ 3,5 —Ç–æ–Ω–Ω –∑–∞–ø—Ä–µ—â–µ–Ω–æ',
    '–í—ä–µ–∑–¥ –∑–∞–ø—Ä–µ—â—ë–Ω',
    '–û–±—â–µ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ',
    '–û–ø–∞—Å–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç –Ω–∞–ª–µ–≤–æ',
    '–û–ø–∞—Å–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç –Ω–∞–ø—Ä–∞–≤–æ',
    '–î–≤–æ–π–Ω–æ–π –ø–æ–≤–æ—Ä–æ—Ç',
    '–ù–µ—Ä–æ–≤–Ω–∞—è –¥–æ—Ä–æ–≥–∞',
    '–°–∫–æ–ª—å–∑–∫–∞—è –¥–æ—Ä–æ–≥–∞',
    '–°—É–∂–µ–Ω–∏–µ –¥–æ—Ä–æ–≥–∏ —Å–ø—Ä–∞–≤–∞',
    '–î–æ—Ä–æ–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
    '–°–≤–µ—Ç–æ—Ñ–æ—Ä–Ω–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ',
    '–ü–µ—à–µ—Ö–æ–¥—ã',
    '–î–µ—Ç–∏',
    '–í–µ–ª–æ—Å–∏–ø–µ–¥–∏—Å—Ç—ã',
    '–û—Å—Ç–æ—Ä–æ–∂–Ω–æ: –ª—ë–¥ / —Å–Ω–µ–≥',
    '–î–∏–∫–∏–µ –∂–∏–≤–æ—Ç–Ω—ã–µ',
    '–ö–æ–Ω–µ—Ü –≤—Å–µ—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –æ–±–≥–æ–Ω–∞',
    '–ü–æ–≤–æ—Ä–æ—Ç –Ω–∞–ø—Ä–∞–≤–æ',
    '–ü–æ–≤–æ—Ä–æ—Ç –Ω–∞–ª–µ–≤–æ',
    '–î–≤–∏–∂–µ–Ω–∏–µ –ø—Ä—è–º–æ',
    '–î–≤–∏–∂–µ–Ω–∏–µ –ø—Ä—è–º–æ –∏–ª–∏ –Ω–∞–ø—Ä–∞–≤–æ',
    '–î–≤–∏–∂–µ–Ω–∏–µ –ø—Ä—è–º–æ –∏–ª–∏ –Ω–∞–ª–µ–≤–æ',
    '–î–µ—Ä–∂–∞—Ç—å—Å—è –ø—Ä–∞–≤–æ–π —Å—Ç–æ—Ä–æ–Ω—ã',
    '–î–µ—Ä–∂–∞—Ç—å—Å—è –ª–µ–≤–æ–π —Å—Ç–æ—Ä–æ–Ω—ã',
    '–ö—Ä—É–≥–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ',
    '–ö–æ–Ω–µ—Ü –∑–∞–ø—Ä–µ—Ç–∞ –æ–±–≥–æ–Ω–∞',
    '–ö–æ–Ω–µ—Ü –∑–∞–ø—Ä–µ—Ç–∞ –æ–±–≥–æ–Ω–∞ –¥–ª—è –¢–° –±–æ–ª–µ–µ 3,5 —Ç–æ–Ω–Ω'
]

# ================= TRANSFORM =================
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# ================= MODEL =================
class CheckImage(nn.Module):
    def __init__(self):
        super().__init__()

        # üî¥ –ò–ú–ï–ù–ê –°–õ–û–Å–í –û–°–¢–ê–í–õ–ï–ù–´ –ö–ê–ö –í .pth
        self.first = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout2d(0.25),

            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout2d(0.25),

            nn.AdaptiveAvgPool2d((1, 1))  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï
        )

        self.second = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 43)
        )

    def forward(self, x):
        x = self.first(x)
        x = self.second(x)
        return x


# ================= DEVICE =================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ================= LOAD MODEL =================
model = CheckImage()
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.to(device)
model.eval()

# ================= API =================
@model_router.post('/predict')
async def check_image(file: UploadFile = File(...)):
    try:
        data = await file.read()
        if not data:
            raise HTTPException(status_code=400, detail='–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω–æ')

        image = Image.open(io.BytesIO(data)).convert("RGB")
        img_tensor = transform(image).unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            confidence, class_id = torch.max(probs, dim=1)

        return {
            "name": class_names[class_id.item()],
            "confidence": f"{round(confidence.item() * 100, 2)}%"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
